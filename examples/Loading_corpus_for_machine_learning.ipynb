{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal example\n",
    "\n",
    "The example uses a very small sample size, yielding relatively coarse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpussearch import ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalize\n",
    "\n",
    "Using the test data in pathDF, which is a CSV file. The preamble is in German. Logging is enabled, and model parameters are chosen according to the small sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml1 = ml(\n",
    "        '../corpussearch/tests/data/dfTest.csv',\n",
    "        dataType='csv',\n",
    "        language='german',\n",
    "        showLogging=True,\n",
    "        model_params=(4,1,5)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the loaded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>part</th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JOHANNES                  KEPLER\\nG ESAMMEL T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>HERAUSGEGEBEN 1M AUFTRAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DER DEUTSCHEN FORSCHUNGSGEMEINSCHAFT\\n       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume        part  page  paragraph  sentence  \\\n",
       "0  Band_1  Einleitung     1          1         1   \n",
       "1  Band_1  Einleitung     1          3         1   \n",
       "2  Band_1  Einleitung     1          4         1   \n",
       "\n",
       "                                                text  \n",
       "0   JOHANNES                  KEPLER\\nG ESAMMEL T...  \n",
       "1                           HERAUSGEGEBEN 1M AUFTRAG  \n",
       "2   DER DEUTSCHEN FORSCHUNGSGEMEINSCHAFT\\n       ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml1.dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the actual training. This automatically cleans the text column, creates a training_data column, and builds the vocabulary for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-21 13:17:56,031 : INFO : collecting all words and their counts\n",
      "2018-03-21 13:17:56,032 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-21 13:17:56,034 : INFO : collected 69 word types from a corpus of 73 raw words and 10 sentences\n",
      "2018-03-21 13:17:56,035 : INFO : Loading a fresh vocabulary\n",
      "2018-03-21 13:17:56,036 : INFO : min_count=1 retains 69 unique words (100% of original 69, drops 0)\n",
      "2018-03-21 13:17:56,037 : INFO : min_count=1 leaves 73 word corpus (100% of original 73, drops 0)\n",
      "2018-03-21 13:17:56,039 : INFO : deleting the raw counts dictionary of 69 items\n",
      "2018-03-21 13:17:56,040 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2018-03-21 13:17:56,042 : INFO : downsampling leaves estimated 24 word corpus (33.0% of prior 73)\n",
      "2018-03-21 13:17:56,043 : INFO : estimated required memory for 69 words and 5 dimensions: 37260 bytes\n",
      "2018-03-21 13:17:56,044 : INFO : resetting layer weights\n",
      "2018-03-21 13:17:56,047 : INFO : training model with 4 workers on 69 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-21 13:17:56,068 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-21 13:17:56,070 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-21 13:17:56,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-21 13:17:56,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-21 13:17:56,074 : INFO : EPOCH - 1 : training on 73 raw words (30 effective words) took 0.0s, 4777 effective words/s\n",
      "2018-03-21 13:17:56,080 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-21 13:17:56,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-21 13:17:56,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-21 13:17:56,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-21 13:17:56,087 : INFO : EPOCH - 2 : training on 73 raw words (25 effective words) took 0.0s, 3214 effective words/s\n",
      "2018-03-21 13:17:56,094 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-21 13:17:56,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-21 13:17:56,097 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-21 13:17:56,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-21 13:17:56,099 : INFO : EPOCH - 3 : training on 73 raw words (20 effective words) took 0.0s, 4194 effective words/s\n",
      "2018-03-21 13:17:56,109 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-21 13:17:56,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-21 13:17:56,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-21 13:17:56,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-21 13:17:56,114 : INFO : EPOCH - 4 : training on 73 raw words (23 effective words) took 0.0s, 4863 effective words/s\n",
      "2018-03-21 13:17:56,118 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-21 13:17:56,120 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-21 13:17:56,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-21 13:17:56,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-21 13:17:56,123 : INFO : EPOCH - 5 : training on 73 raw words (17 effective words) took 0.0s, 3309 effective words/s\n",
      "2018-03-21 13:17:56,124 : INFO : training on a 365 raw words (115 effective words) took 0.1s, 1518 effective words/s\n",
      "2018-03-21 13:17:56,125 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "ml1.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has been extended with the training_data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>part</th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>training_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JOHANNES                  KEPLER\\nG ESAMMEL T...</td>\n",
       "      <td>[johannes, kepler, esammel, te, werke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>HERAUSGEGEBEN 1M AUFTRAG</td>\n",
       "      <td>[herausgegeben, m, auftrag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Band_1</td>\n",
       "      <td>Einleitung</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DER DEUTSCHEN FORSCHUNGSGEMEINSCHAFT\\n       ...</td>\n",
       "      <td>[deutschen, forschungsgemeinschaft, bayerische...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume        part  page  paragraph  sentence  \\\n",
       "0  Band_1  Einleitung     1          1         1   \n",
       "1  Band_1  Einleitung     1          3         1   \n",
       "2  Band_1  Einleitung     1          4         1   \n",
       "\n",
       "                                                text  \\\n",
       "0   JOHANNES                  KEPLER\\nG ESAMMEL T...   \n",
       "1                           HERAUSGEGEBEN 1M AUFTRAG   \n",
       "2   DER DEUTSCHEN FORSCHUNGSGEMEINSCHAFT\\n       ...   \n",
       "\n",
       "                                       training_data  \n",
       "0             [johannes, kepler, esammel, te, werke]  \n",
       "1                        [herausgegeben, m, auftrag]  \n",
       "2  [deutschen, forschungsgemeinschaft, bayerische...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml1.dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "One can then use the model to get words in similar contexts. If a word is not included in the original training vocabulary, a similar word is chosen using difflib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-21 13:18:00,416 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using similar word: einleitung\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wisse', 0.9392784833908081),\n",
       " ('akademie', 0.8966387510299683),\n",
       " ('chronologische', 0.8298858404159546),\n",
       " ('werken', 0.6740391254425049),\n",
       " ('caspar', 0.6174360513687134),\n",
       " ('zumeist', 0.6168584823608398),\n",
       " ('stellen', 0.5765997767448425),\n",
       " ('gesamten', 0.5361281037330627),\n",
       " ('auberen', 0.5259561538696289),\n",
       " ('schaffens', 0.5060181617736816)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml1.getSimilarContext('Einleitung')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
